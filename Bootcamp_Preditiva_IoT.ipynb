{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fa16bbe",
   "metadata": {},
   "source": [
    "# Bootcamp Ciência de Dados e IA – Manutenção Preditiva (IoT)\n",
    "\n",
    "**Objetivo**: desenvolver um sistema que **prediz a classe do defeito** (entre 5 possíveis) e **retorna a probabilidade associada**, além de extrair **insights operacionais** e **visualizações** a partir de medidas de sensores de máquinas industriais.\n",
    "\n",
    "**Arquivos**:\n",
    "- `Bootcamp_train.csv`: treino/validação\n",
    "- `Bootcamp_test.csv`: teste (sem rótulos) – gerar predições e enviar à API do desafio\n",
    "\n",
    "> **Observação**: Este notebook foi gerado para ser executável de ponta a ponta. Se os arquivos CSV **não** estiverem presentes na pasta atual, ele **simula** um conjunto de dados sintético com o mesmo esquema para permitir a execução completa e a inspeção do pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94ba2e6",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef9ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Opcional) Caso deseje usar LightGBM/CatBoost/SHAP/Optuna, descomente:\n",
    "# %pip install lightgbm catboost shap optuna\n",
    "\n",
    "import warnings, os\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    f1_score, log_loss, roc_auc_score, precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "plt.rcParams['figure.figsize']=(7,5)\n",
    "plt.rcParams['axes.grid']=True\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.max_columns', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9a3cb9-7e00-4c8a-9445-ab0c9adb8531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (2.3.2)\n",
      "Collecting scipy>=1.8.0\n",
      "  Downloading scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.4/35.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.4/308.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.1 scipy-1.16.1 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c919eb7",
   "metadata": {},
   "source": [
    "## 2. Configurações do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "277f6627",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = Path('./dataset/bootcamp_train.csv')\n",
    "TEST_PATH  = Path('./dataset/bootcamp_train.csv')\n",
    "PROBLEM_KIND = 'multiclass'  # ou 'multilabel'\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.20\n",
    "OUT_DIR = Path('./outputs'); OUT_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02428c9d",
   "metadata": {},
   "source": [
    "## 3. Carregamento dos Dados (ou Simulação)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05809e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train não encontrado. Simulando dados...\n",
      "Test não encontrado. Simulando dados...\n",
      "(6000, 16) (1500, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_produto</th>\n",
       "      <th>tipo</th>\n",
       "      <th>temperatura_ar</th>\n",
       "      <th>temperatura_processo</th>\n",
       "      <th>umidade_relativa</th>\n",
       "      <th>velocidade_rotacional</th>\n",
       "      <th>torque</th>\n",
       "      <th>desgaste_da_ferramenta</th>\n",
       "      <th>classe_defeito</th>\n",
       "      <th>FDF</th>\n",
       "      <th>FDC</th>\n",
       "      <th>FP</th>\n",
       "      <th>FTE</th>\n",
       "      <th>FA</th>\n",
       "      <th>falha_maquina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1377</td>\n",
       "      <td>L</td>\n",
       "      <td>299.204370</td>\n",
       "      <td>323.710407</td>\n",
       "      <td>50.578200</td>\n",
       "      <td>1354.886565</td>\n",
       "      <td>38.056956</td>\n",
       "      <td>104.681018</td>\n",
       "      <td>FDF</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1250</td>\n",
       "      <td>H</td>\n",
       "      <td>300.743964</td>\n",
       "      <td>310.018732</td>\n",
       "      <td>32.274149</td>\n",
       "      <td>1475.727050</td>\n",
       "      <td>42.721579</td>\n",
       "      <td>64.209308</td>\n",
       "      <td>sem_falha</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1273</td>\n",
       "      <td>M</td>\n",
       "      <td>297.769044</td>\n",
       "      <td>323.096653</td>\n",
       "      <td>34.448053</td>\n",
       "      <td>1732.120412</td>\n",
       "      <td>26.454887</td>\n",
       "      <td>28.565750</td>\n",
       "      <td>sem_falha</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1358</td>\n",
       "      <td>H</td>\n",
       "      <td>299.711082</td>\n",
       "      <td>320.233333</td>\n",
       "      <td>55.149489</td>\n",
       "      <td>1755.263409</td>\n",
       "      <td>43.320499</td>\n",
       "      <td>26.848181</td>\n",
       "      <td>sem_falha</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1231</td>\n",
       "      <td>H</td>\n",
       "      <td>304.946226</td>\n",
       "      <td>318.255694</td>\n",
       "      <td>36.994232</td>\n",
       "      <td>1653.436067</td>\n",
       "      <td>27.869880</td>\n",
       "      <td>22.598292</td>\n",
       "      <td>sem_falha</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id id_produto tipo  temperatura_ar  temperatura_processo  umidade_relativa  \\\n",
       "0   0       1377    L      299.204370            323.710407         50.578200   \n",
       "1   1       1250    H      300.743964            310.018732         32.274149   \n",
       "2   2       1273    M      297.769044            323.096653         34.448053   \n",
       "3   3       1358    H      299.711082            320.233333         55.149489   \n",
       "4   4       1231    H      304.946226            318.255694         36.994232   \n",
       "\n",
       "   velocidade_rotacional     torque  desgaste_da_ferramenta classe_defeito  \\\n",
       "0            1354.886565  38.056956              104.681018            FDF   \n",
       "1            1475.727050  42.721579               64.209308      sem_falha   \n",
       "2            1732.120412  26.454887               28.565750      sem_falha   \n",
       "3            1755.263409  43.320499               26.848181      sem_falha   \n",
       "4            1653.436067  27.869880               22.598292      sem_falha   \n",
       "\n",
       "   FDF  FDC  FP  FTE  FA  falha_maquina  \n",
       "0    1    0   0    0   0              1  \n",
       "1    0    0   0    0   0              0  \n",
       "2    0    0   0    0   0              0  \n",
       "3    0    0   0    0   0              0  \n",
       "4    0    0   0    0   0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simulate_data(n=6000, seed=7):\n",
    "    rng=np.random.default_rng(seed)\n",
    "    df=pd.DataFrame({'id':np.arange(n),'id_produto':rng.integers(1000,1400,size=n).astype(str),'tipo':rng.choice(list('LMH'),size=n,p=[0.45,0.35,0.20])})\n",
    "    df['temperatura_ar']=rng.normal(300,5,n)\n",
    "    df['temperatura_processo']=df['temperatura_ar']+rng.normal(15,8,n)\n",
    "    df['umidade_relativa']=np.clip(rng.normal(45,12,n),5,95)\n",
    "    df['velocidade_rotacional']=np.clip(rng.normal(1500,200,n),200,4000)\n",
    "    df['torque']=np.clip(rng.normal(40,8,n),5,120)\n",
    "    df['desgaste_da_ferramenta']=np.clip(rng.normal(80,50,n),0,500)\n",
    "    delta_T=df['temperatura_processo']-df['temperatura_ar']\n",
    "    potencia_rel=(df['velocidade_rotacional']*df['torque'])/(np.max(df['velocidade_rotacional'])*np.max(df['torque']))\n",
    "    estresse_termico=delta_T*(1+(df['umidade_relativa']/100.0)*0.3)\n",
    "    desgaste_risco=df['desgaste_da_ferramenta']/(df['desgaste_da_ferramenta'].max()+1e-9)\n",
    "    tensao_excessiva=potencia_rel*(df['velocidade_rotacional']/df['velocidade_rotacional'].max())\n",
    "    p_FDF=0.08+0.35*np.clip(desgaste_risco,0,1)\n",
    "    p_FDC=0.05+0.25*np.clip(estresse_termico/(estresse_termico.max()+1e-9),0,1)\n",
    "    p_FP=0.04+0.30*np.clip(potencia_rel,0,1)\n",
    "    p_FTE=0.03+0.25*np.clip(tensao_excessiva,0,1)\n",
    "    p_FA=0.03+0.05*rng.random(n)\n",
    "    ps=np.vstack([p_FDF,p_FDC,p_FP,p_FTE,p_FA]).T\n",
    "    max_p=ps.max(axis=1)\n",
    "    no_fail_thresh=np.percentile(max_p,60)\n",
    "    classes=np.where(max_p<no_fail_thresh,'sem_falha',np.array(['FDF','FDC','FP','FTE','FA'])[ps.argmax(axis=1)])\n",
    "    df['classe_defeito']=classes\n",
    "    for c in ['FDF','FDC','FP','FTE','FA']:\n",
    "        df[c]=(df['classe_defeito']==c).astype(int)\n",
    "    df['falha_maquina']=(df['classe_defeito']!='sem_falha').astype(int)\n",
    "    return df\n",
    "from pathlib import Path\n",
    "if Path('Bootcamp_train.csv').exists():\n",
    "    train=pd.read_csv('Bootcamp_train.csv'); print('Train carregado de Bootcamp_train.csv')\n",
    "else:\n",
    "    print('Train não encontrado. Simulando dados...'); train=simulate_data(6000,7)\n",
    "if Path('Bootcamp_test.csv').exists():\n",
    "    test=pd.read_csv('Bootcamp_test.csv'); print('Test carregado de Bootcamp_test.csv')\n",
    "else:\n",
    "    print('Test não encontrado. Simulando dados...'); test=simulate_data(1500,17).drop(columns=['classe_defeito','FDF','FDC','FP','FTE','FA','falha_maquina'],errors='ignore')\n",
    "print(train.shape,test.shape); train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4237a910",
   "metadata": {},
   "source": [
    "## 4. Qualidade dos Dados e Consistência dos Rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6dd77d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões: (6000, 16)\n",
      "\n",
      "Tipos:\n",
      "id                          int64\n",
      "id_produto                 object\n",
      "tipo                       object\n",
      "temperatura_ar            float64\n",
      "temperatura_processo      float64\n",
      "umidade_relativa          float64\n",
      "velocidade_rotacional     float64\n",
      "torque                    float64\n",
      "desgaste_da_ferramenta    float64\n",
      "classe_defeito             object\n",
      "FDF                         int64\n",
      "FDC                         int64\n",
      "FP                          int64\n",
      "FTE                         int64\n",
      "FA                          int64\n",
      "falha_maquina               int64\n",
      "dtype: object\n",
      "\n",
      "Valores ausentes (%):\n",
      "Series([], dtype: float64)\n",
      "\n",
      "Duplicatas: 0\n",
      "\n",
      "Ocorrências de múltiplas falhas simultâneas:\n",
      "sum_fail_bins\n",
      "0    3600\n",
      "1    2400\n",
      "Name: count, dtype: int64\n",
      "Inconsistências falha_maquina=0 porém alguma falha binária=1: 0\n"
     ]
    }
   ],
   "source": [
    "def data_quality_report(df):\n",
    "    print('Dimensões:',df.shape)\n",
    "    print('\\nTipos:'); print(df.dtypes)\n",
    "    print('\\nValores ausentes (%):'); na=df.isna().mean().sort_values(ascending=False)*100; print(na[na>0].round(2))\n",
    "    print('\\nDuplicatas:',df.duplicated().sum())\n",
    "data_quality_report(train)\n",
    "label_cols=['FDF','FDC','FP','FTE','FA']\n",
    "if set(label_cols).issubset(train.columns):\n",
    "    train['sum_fail_bins']=train[label_cols].sum(axis=1)\n",
    "    print('\\nOcorrências de múltiplas falhas simultâneas:'); print(train['sum_fail_bins'].value_counts().sort_index())\n",
    "    if 'falha_maquina' in train.columns:\n",
    "        inco=((train['falha_maquina']==0)&(train['sum_fail_bins']>0)).sum(); print('Inconsistências falha_maquina=0 porém alguma falha binária=1:',inco)\n",
    "    train.drop(columns=['sum_fail_bins'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28c7f7a",
   "metadata": {},
   "source": [
    "## 5. Definição do Problema e Construção do Alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aded03d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['sem_falha', 'FDF', 'FDC', 'FP', 'FTE', 'FA']\n",
      "Distribuição:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'value_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m y,classes=build_targets(train,PROBLEM_KIND)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mClasses:\u001b[39m\u001b[33m'\u001b[39m,classes)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mDistribuição:\u001b[39m\u001b[33m'\u001b[39m); \u001b[38;5;28mprint\u001b[39m(y.value_counts() \u001b[38;5;28;01mif\u001b[39;00m PROBLEM_KIND==\u001b[33m'\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m y.sum().sort_values(ascending=\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'value_counts'"
     ]
    }
   ],
   "source": [
    "def build_targets(df,kind='multiclass'):\n",
    "    label_cols=['FDF','FDC','FP','FTE','FA']\n",
    "    if kind=='multiclass':\n",
    "        if 'classe_defeito' in df.columns:\n",
    "            y=df['classe_defeito'].astype(str)\n",
    "        elif set(label_cols).issubset(df.columns):\n",
    "            def to_class(row):\n",
    "                for c in label_cols:\n",
    "                    if row[c]==1: return c\n",
    "                return 'sem_falha'\n",
    "            y=df[label_cols].apply(to_class,axis=1)\n",
    "        else:\n",
    "            raise ValueError('Faltam rótulos.')\n",
    "        classes=['sem_falha','FDF','FDC','FP','FTE','FA']\n",
    "        y=pd.Categorical(y,categories=classes).astype(str)\n",
    "        return y,classes\n",
    "    else:\n",
    "        assert set(label_cols).issubset(df.columns)\n",
    "        return df[label_cols].astype(int).copy(),label_cols\n",
    "y,classes=build_targets(train,PROBLEM_KIND)\n",
    "print('Classes:',classes)\n",
    "print('Distribuição:'); print(y.value_counts() if PROBLEM_KIND=='multiclass' else y.sum().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613963cc",
   "metadata": {},
   "source": [
    "## 6. Seleção de Atributos (Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb2f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_COLS=['tipo']\n",
    "NUM_COLS=['temperatura_ar','temperatura_processo','umidade_relativa','velocidade_rotacional','torque','desgaste_da_ferramenta']\n",
    "X=train[CAT_COLS+NUM_COLS].copy(); X_test=test[CAT_COLS+NUM_COLS].copy()\n",
    "print('X:',X.shape,'X_test:',X_test.shape); X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae18c92",
   "metadata": {},
   "source": [
    "## 7. Análise de Balanceamento do Alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b6d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "if PROBLEM_KIND=='multiclass':\n",
    "    counts=y.value_counts().reindex(classes,fill_value=0)\n",
    "    fig,ax=plt.subplots(); ax.bar(counts.index.astype(str),counts.values)\n",
    "    ax.set_title('Distribuição de classes'); ax.set_xlabel('Classe'); ax.set_ylabel('Contagem'); plt.show()\n",
    "else:\n",
    "    sums=y.sum().reindex(classes,fill_value=0)\n",
    "    fig,ax=plt.subplots(); ax.bar(sums.index.astype(str),sums.values)\n",
    "    ax.set_title('Positivos por classe'); ax.set_xlabel('Classe'); ax.set_ylabel('N positivos'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5ebc6",
   "metadata": {},
   "source": [
    "## 8. Divisão Treino/Validação e Pesos de Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c34517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "if PROBLEM_KIND=='multiclass':\n",
    "    X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.20,stratify=y,random_state=42)\n",
    "    vc=pd.Series(y_train).value_counts().reindex(classes,fill_value=1)\n",
    "    inv=1.0/vc; class_weight=(inv/inv.mean()).to_dict(); sample_weight=pd.Series(y_train).map(class_weight).values\n",
    "else:\n",
    "    X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.20,random_state=42); sample_weight=None\n",
    "print('Shapes:',X_train.shape,X_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60083223",
   "metadata": {},
   "source": [
    "## 9. Modelo e Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13debb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "pre=ColumnTransformer([('cat',OneHotEncoder(handle_unknown='ignore'),['tipo']),('num','passthrough',NUM_COLS)],remainder='drop')\n",
    "if PROBLEM_KIND=='multiclass':\n",
    "    base_model=HistGradientBoostingClassifier(learning_rate=0.10,max_iter=220,min_samples_leaf=25,random_state=42)\n",
    "    pipe_base=Pipeline([('pre',pre),('clf',base_model)])\n",
    "    clf=CalibratedClassifierCV(base_estimator=pipe_base,method='isotonic',cv=3)\n",
    "    clf.fit(X_train,y_train,**({'clf__sample_weight':sample_weight} if sample_weight is not None else {}))\n",
    "else:\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "    base_model=HistGradientBoostingClassifier(learning_rate=0.10,max_iter=220,min_samples_leaf=25,random_state=42)\n",
    "    clf=Pipeline([('pre',pre),('ovr',OneVsRestClassifier(base_model))])\n",
    "    clf.fit(X_train,y_train)\n",
    "print('Modelo treinado.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c5caaa",
   "metadata": {},
   "source": [
    "## 10. Avaliação no Conjunto de Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93332666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "if PROBLEM_KIND=='multiclass':\n",
    "    proba_val=clf.predict_proba(X_val); y_pred=clf.predict(X_val); labels=np.array(['sem_falha','FDF','FDC','FP','FTE','FA'])\n",
    "    macro_f1=f1_score(y_val,y_pred,average='macro'); ll=log_loss(y_val,proba_val,labels=labels); y_val_idx=pd.Categorical(y_val,categories=labels).codes\n",
    "    ovr_auc=roc_auc_score(y_val_idx,proba_val,multi_class='ovr'); print(f'Macro-F1: {macro_f1:.4f} | LogLoss: {ll:.4f} | ROC-AUC OvR: {ovr_auc:.4f}')\n",
    "    print('\\nClassification report:'); print(classification_report(y_val,y_pred,zero_division=0))\n",
    "    cm=confusion_matrix(y_val,y_pred,labels=labels,normalize='true'); fig,ax=plt.subplots(figsize=(7,7)); disp=ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=labels)\n",
    "    disp.plot(ax=ax,values_format='.2f',colorbar=False); ax.set_title('Matriz de confusão normalizada (val)'); plt.show()\n",
    "    fig,ax=plt.subplots(figsize=(7,6))\n",
    "    for i,cls in enumerate(labels):\n",
    "        y_true_cls=(pd.Series(y_val).values==cls).astype(int)\n",
    "        precision,recall,_=precision_recall_curve(y_true_cls,proba_val[:,i]); ap=average_precision_score(y_true_cls,proba_val[:,i])\n",
    "        ax.plot(recall,precision,label=f'{cls} (AP={ap:.2f})')\n",
    "    ax.set_xlabel('Recall'); ax.set_ylabel('Precision'); ax.set_title('Precision–Recall (OvR)'); ax.legend(loc='best'); plt.show()\n",
    "    top1_conf=proba_val.max(axis=1); top1_correct=(y_pred==pd.Series(y_val).values).astype(int)\n",
    "    prob_true,prob_pred=calibration_curve(top1_correct,top1_conf,n_bins=10,strategy='uniform'); fig,ax=plt.subplots(figsize=(6,6))\n",
    "    ax.plot(prob_pred,prob_true,marker='o'); ax.plot([0,1],[0,1],'--'); ax.set_xlabel('Probabilidade prevista (Top-1)'); ax.set_ylabel('Fração de acertos'); ax.set_title('Reliability diagram (Top-1)'); plt.show()\n",
    "    pipe_base=Pipeline([('pre',pre),('clf',HistGradientBoostingClassifier(learning_rate=0.10,max_iter=220,min_samples_leaf=25,random_state=42))])\n",
    "    pipe_base.fit(X_train,y_train,**({'clf__sample_weight':sample_weight} if sample_weight is not None else {}))\n",
    "    perm=permutation_importance(pipe_base,X_val,y_val,n_repeats=8,random_state=42)\n",
    "    ohe=pipe_base.named_steps['pre'].named_transformers_['cat']; feat_names=list(ohe.get_feature_names_out(['tipo']))+['temperatura_ar','temperatura_processo','umidade_relativa','velocidade_rotacional','torque','desgaste_da_ferramenta']\n",
    "    imp_df=pd.DataFrame({'feature':feat_names,'importance_mean':perm.importances_mean,'importance_std':perm.importances_std}).sort_values('importance_mean',ascending=False)\n",
    "    display(imp_df.head(15)); fig,ax=plt.subplots(figsize=(8,6)); ax.barh(imp_df['feature'],imp_df['importance_mean']); ax.invert_yaxis(); ax.set_xlabel('Queda média de score'); ax.set_title('Importâncias por permutação (val)'); plt.show()\n",
    "else:\n",
    "    Y_proba=clf.predict_proba(X_val); Y_pred=clf.predict(X_val); f1_macro=f1_score(y_val,Y_pred,average='macro'); print(f'F1 macro: {f1_macro:.4f}')\n",
    "    aps=[]\n",
    "    for i,c in enumerate(classes):\n",
    "        ap=average_precision_score(y_val[c].values,Y_proba[:,i]); aps.append(ap)\n",
    "    print('AP por classe:',{c:round(a,3) for c,a in zip(classes,aps)}); print('AP médio:',np.mean(aps).round(4))\n",
    "    fig,ax=plt.subplots(figsize=(7,6))\n",
    "    for i,c in enumerate(classes):\n",
    "        precision,recall,_=precision_recall_curve(y_val[c].values,Y_proba[:,i]); ap=average_precision_score(y_val[c].values,Y_proba[:,i])\n",
    "        ax.plot(recall,precision,label=f'{c} (AP={ap:.2f})')\n",
    "    ax.set_xlabel('Recall'); ax.set_ylabel('Precision'); ax.set_title('Precision–Recall (multirrótulo)'); ax.legend(loc='best'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec6c75",
   "metadata": {},
   "source": [
    "## 11. Predição no Conjunto de Teste e Arquivo de Submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e51d53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROBLEM_KIND=='multiclass':\n",
    "    proba_test=clf.predict_proba(X_test); pred_test=clf.predict(X_test); labels=np.array(['sem_falha','FDF','FDC','FP','FTE','FA'])\n",
    "    sub=pd.DataFrame({'id':test['id'] if 'id' in test.columns else np.arange(len(test)),'pred_class':pred_test})\n",
    "    for i,cls in enumerate(labels): sub[f'proba_{cls}']=proba_test[:,i]\n",
    "    sub_path=OUT_DIR/'submission_multiclass.csv'; sub.to_csv(sub_path,index=False); print('Arquivo de submissão salvo em:',sub_path)\n",
    "else:\n",
    "    Y_proba_test=clf.predict_proba(X_test)\n",
    "    if isinstance(Y_proba_test,list): Y_proba_test=np.vstack([p[:,1] for p in Y_proba_test]).T\n",
    "    sub=pd.DataFrame({'id':test['id'] if 'id' in test.columns else np.arange(len(test))})\n",
    "    for i,cls in enumerate(classes): sub[f'proba_{cls}']=Y_proba_test[:,i]\n",
    "    sub_path=OUT_DIR/'submission_multilabel.csv'; sub.to_csv(sub_path,index=False); print('Arquivo de submissão salvo em:',sub_path)\n",
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d5148c",
   "metadata": {},
   "source": [
    "## 12. (Opcional) Validação Cruzada Estratificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de4b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROBLEM_KIND=='multiclass':\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    skf=StratifiedKFold(n_splits=5,shuffle=True,random_state=42); scores=[]\n",
    "    for fold,(tr,va) in enumerate(skf.split(X,y),1):\n",
    "        X_tr,X_va=X.iloc[tr],X.iloc[va]; y_tr,y_va=pd.Series(y).iloc[tr],pd.Series(y).iloc[va]\n",
    "        vc=y_tr.value_counts().reindex(classes,fill_value=1); inv=1.0/vc; cw=(inv/inv.mean()).to_dict(); sw=y_tr.map(cw).values\n",
    "        pipe=Pipeline([('pre',pre),('clf',HistGradientBoostingClassifier(learning_rate=0.10,max_iter=220,min_samples_leaf=25,random_state=42))])\n",
    "        cal=CalibratedClassifierCV(base_estimator=pipe,method='isotonic',cv=3); cal.fit(X_tr,y_tr,clf__sample_weight=sw)\n",
    "        proba_va=cal.predict_proba(X_va); y_hat=cal.predict(X_va); f1m=f1_score(y_va,y_hat,average='macro'); ll=log_loss(y_va,proba_va,labels=np.array(classes))\n",
    "        scores.append((f1m,ll)); print(f'Fold {fold}: F1m={f1m:.4f} | LogLoss={ll:.4f}')\n",
    "    print('\\nMédia (F1m, LogLoss):',np.mean(scores,axis=0).round(4))\n",
    "else:\n",
    "    print('Para multirrótulo, use KFold simples ou estratificação multirrótulo.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892dc955",
   "metadata": {},
   "source": [
    "## 13. Próximos Passos e Extensões\n",
    "- **Engenharia de atributos** (`delta_T`, razões, interações físicas)\n",
    "- **Modelos**: LightGBM / CatBoost; ensembles (stacking)\n",
    "- **Calibração por classe (multirrótulo)** com `CalibratedClassifierCV` por rótulo\n",
    "- **Explainability**: SHAP (global/local) para insights operacionais\n",
    "- **Tuning**: GridSearchCV/Optuna, early stopping\n",
    "- **MLOps**: MLflow, testes de dados, CI/CD\n",
    "- **API**: FastAPI para servir o modelo\n",
    "- **Dashboard**: Streamlit para operação e interpretação\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
